{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myung\\AppData\\Local\\Temp\\ipykernel_14260\\3511293057.py:16: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('Fwd_Header_Length.1', 'Fwd_Header_Length1')\n",
      "C:\\Users\\myung\\AppData\\Local\\Temp\\ipykernel_14260\\3511293057.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df.columns = df.columns.str.replace('Fwd_Header_Length.1', 'Fwd_Header_Length1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fwd_Packet_Length_Max: 0.08540890541602585\n",
      "Init_Win_bytes_forward: 0.07822741276620575\n",
      "Subflow_Fwd_Bytes: 0.07331976366751264\n",
      "Fwd_Packet_Length_Mean: 0.06881392168678165\n",
      "Subflow_Fwd_Packets: 0.056774166925017536\n",
      "Avg_Fwd_Segment_Size: 0.05488781857205268\n",
      "Destination_Port: 0.051909297009655034\n",
      "Bwd_Packet_Length_Min: 0.0495258279438441\n",
      "Total_Length_of_Fwd_Packets: 0.04791388369574302\n",
      "act_data_pkt_fwd: 0.04097751951760758\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "#load data and ensure it's good\n",
    "df = pd.read_csv(\"./Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "\n",
    "df.columns = df.columns.str.lstrip()\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.replace('/s', '_s')\n",
    "df.columns = df.columns.str.replace('Fwd_Header_Length.1', 'Fwd_Header_Length1')\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df=df.fillna(0)\n",
    "df[\"Target\"] = np.where(df[\"Label\"] == \"BENIGN\", 0, 1)\n",
    "\n",
    "features = np.float32(df.loc[:, ~df.columns.isin(['Flow_ID', 'Source_IP', 'Destination_IP', 'Timestamp', 'Label', 'Target'])].copy().values) #reduce memory usage\n",
    "label = df.loc[:, df.columns.isin(['Target'])].copy().values.ravel()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "df = pd.read_csv(\"./Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "\n",
    "df.columns = df.columns.str.lstrip()\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.replace('/s', '_s')\n",
    "df.columns = df.columns.str.replace('Fwd_Header_Length.1', 'Fwd_Header_Length1')\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df=df.fillna(0)\n",
    "df[\"Target\"] = np.where(df[\"Label\"] == \"BENIGN\", 0, 1)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier #use this when label is categorical\n",
    "\n",
    "# Train a random forest classifier on the dataset\n",
    "forest = RandomForestClassifier(n_estimators = 100, random_state=42)\n",
    "forest.fit(features, label)\n",
    "\n",
    "# Get the feature importances and sort them in descending order\n",
    "importances = forest.feature_importances_\n",
    "sorted_indices = importances.argsort()[::-1]\n",
    "feature_names = df.loc[:, ~df.columns.isin(['Flow_ID', 'Source_IP', 'Destination_IP', 'Timestamp', 'Label', 'Target'])].copy().columns\n",
    "\n",
    "# Print the top 10 features by importance\n",
    "top_features = 10\n",
    "for index in sorted_indices[:top_features]:\n",
    "    print(f\"{feature_names[index]}: {importances[index]}\")\n",
    "\n",
    " \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.model_selection import learning_curve\n",
    "import plotly.graph_objs as go\n",
    "import plotly.subplots as sp\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define the models to use\n",
    "# Define the models to use\n",
    "models = {\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Boruta\": BorutaPy(RandomForestClassifier(), n_estimators=\"auto\", verbose=0)\n",
    "}\n",
    "\n",
    "X = np.float32(df.loc[:, df.columns.isin(['Fwd_Packet_Length_Mean', 'Fwd_Packet_Length_Max', \"act_data_pkt_fwd\", \"Avg_Fwd_Segment_Size\", \"Fwd_IAT_Std\",\n",
    "        \"Subflow_Fwd_Bytes\", \"Total_Fwd_Packets\", \"Init_Win_bytes_forward\", \"Fwd_Header_Length1\", \"Destination_Port\"])].copy().values)\n",
    "y = df['Target'].values\n",
    "\n",
    "# Create a subplot with one row and as many columns as there are models\n",
    "fig = sp.make_subplots(rows=1, cols=len(models), subplot_titles=list(models.keys()), shared_yaxes=True)\n",
    "\n",
    "# Plot the learning curve for each model\n",
    "for index, (name, model) in enumerate(models.items()):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5, n_jobs=-1,\n",
    "                                                            train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                            scoring='accuracy')\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Add the training and test scores to the plot\n",
    "    fig.add_trace(go.Scatter(x=train_sizes, y=train_mean, mode='lines+markers', name=\"Training score\", line=dict(color=\"red\")),\n",
    "                  row=1, col=index + 1)\n",
    "    fig.add_trace(go.Scatter(x=train_sizes, y=test_mean, mode='lines+markers', name=\"Testing score\", line=dict(color=\"green\")),\n",
    "                  row=1, col=index + 1)\n",
    "\n",
    "# Update the layout of the plot\n",
    "fig.update_layout(title='Learning Curves for Different Models', xaxis_title=\"Training examples\", yaxis_title=\"Score\", legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1))\n",
    "\n",
    "# Show the interactive plot\n",
    "pio.write_html(fig, file='learning_curves.html', auto_open=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
